{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Desktop/a/backend2/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:458: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/Desktop/a/backend2/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:459: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/Desktop/a/backend2/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:460: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/Desktop/a/backend2/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:461: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/Desktop/a/backend2/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:462: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/Desktop/a/backend2/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:465: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.86 s, sys: 448 ms, total: 3.3 s\n",
      "Wall time: 2.35 s\n",
      "CPU times: user 1min 25s, sys: 2.77 s, total: 1min 28s\n",
      "Wall time: 14.8 s\n",
      "CPU times: user 1min 45s, sys: 2.75 s, total: 1min 48s\n",
      "Wall time: 17.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mrcnn.config\n",
    "from mrcnn import utils, visualize\n",
    "from mrcnn.model import MaskRCNN\n",
    "from pathlib import Path\n",
    "\n",
    "#  Configuration that will be used by Mask R-CNN library\n",
    "\n",
    "class MaskRCNNConfig(mrcnn.config.Config):\n",
    "    NAME = \"coco_pretrained_model_config\"\n",
    "    IMAGES_PER_GPU = 1\n",
    "    GPU_COUNT = 1\n",
    "    NUM_CLASSES = 1 + 80  # COCO dataset has 80 classes + one background class\n",
    "    DETECTION_MIN_CONFIDENCE = 0.6\n",
    "    \n",
    "    \n",
    "# Filter the result of Mask R-CNN to only obtain bounding boxes and class names of objects identified as cars\n",
    "\n",
    "def getCarBoxes(boxes,class_ids):\n",
    "    car_boxes = []\n",
    "    \n",
    "    # class_id 3/8 corresponds to car/truck objects as per COCO dataset\n",
    "    for i,box in enumerate(boxes):\n",
    "        if class_ids[i] in [3,8]:\n",
    "            car_boxes.append(boxes)\n",
    "            \n",
    "    return np.array(car_boxes)\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = \".\"\n",
    "\n",
    "# Local path for logs and trained model.One of the best practices and useful while training the model . \n",
    "# Will not be used in this demonstration\n",
    "MODEL_DIR = os.path.join(ROOT_DIR,\"logs\")\n",
    "\n",
    "\n",
    "# Path for saving trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR,\"mask_rcnn_coco.h5\")\n",
    "\n",
    "\n",
    "# Downloading weights of pre-trained model for COCO dataset from the release \n",
    "# Executed for the first time when to store the model weights in this repo\n",
    "\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "   utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "        \n",
    "\n",
    "# Directory of images to run detection on\n",
    "IMAGE_DIR = \"images\"\n",
    "# /CNR-EXT_FULL_IMAGE_1000x750\"\n",
    "\n",
    "\n",
    "# Create a Mask R-CNN model in inference mode\n",
    "model = MaskRCNN(mode='inference', config=MaskRCNNConfig(),model_dir=MODEL_DIR)\n",
    "\n",
    "\n",
    "# Load pre-trained model, this will load weights of model trained on COCO dataset\n",
    "%time model.load_weights(COCO_MODEL_PATH,by_name=True)\n",
    "\n",
    "\n",
    "# COCO Class names\n",
    "# Index of the class in the list is its ID. For example, to get ID of\n",
    "# the person class, use: class_names.index('person')\n",
    "\n",
    "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "               'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "# Location of parking spaces\n",
    "parked_car_boxes = None\n",
    "\n",
    "# Load a random image from images folder\n",
    "file_names = next(os.walk(IMAGE_DIR))[2]\n",
    "\n",
    "file_names\n",
    "\n",
    "# choose the first and 3rd image from a sequence of file_names \n",
    "# First image is the reference image of completely occupied parking area. It is used for finding all parking spots\n",
    "\n",
    "image1 = skimage.io.imread(os.path.join(IMAGE_DIR,\"item1.jpg\"))\n",
    "image2 = skimage.io.imread(os.path.join(IMAGE_DIR,\"item2.jpg\"))\n",
    "\n",
    "\n",
    "# run detection\n",
    "# runs the detection pipeline and returns a list of dictionaries, one dict per image.\n",
    "\n",
    "%time result1 = model.detect([image1])    \n",
    "\n",
    "\n",
    "%time result2 = model.detect([image2])    \n",
    "\n",
    "r1 = result1[0]\n",
    "r2 = result2[0]\n",
    "\n",
    "\n",
    "visualize.display_instances(image1,r1['rois'],r1['masks'], r1['class_ids'], class_names, r1['scores'])\n",
    "\n",
    "visualize.display_instances(image2,r2['rois'], r2['masks'], r2['class_ids'], class_names, r2['scores'])\n",
    "\n",
    "# Filter the results to only get identified cars' bounding boxes\n",
    "\n",
    "car_boxes1 = getCarBoxes(r1['rois'],r1['class_ids'])\n",
    "car_boxes2 = getCarBoxes(r2['rois'],r2['class_ids'])\n",
    "\n",
    "# car_boxes1 and car_boxes2 is an array of length of no. of cars identified with each row having set of \n",
    "# 4 coordinates y1, x1, y2, x2 ; points 1 and 2 are opposite vertices of the bounding box.\n",
    "\n",
    "car_boxes1[0].shape\n",
    "\n",
    "parking_spaces = car_boxes1[0]\n",
    "\n",
    "# computinig center locations of each spot\n",
    "center_locs = []\n",
    "\n",
    "for spot_coords in parking_spaces:\n",
    "    center_locs.append([int((spot_coords[1]+spot_coords[3])/2), int((spot_coords[0]+spot_coords[2])/2)])\n",
    "\n",
    "\n",
    "centers = np.array(center_locs)\n",
    "    \n",
    "\n",
    "centers.shape\n",
    "\n",
    "# Draw each box on the frame\n",
    "\n",
    "for i,box in enumerate(parking_spaces):\n",
    "    y1, x1, y2, x2 = box\n",
    "    cv2.rectangle(image1, (x1, y1), (x2, y2),(0,0,255),2)\n",
    "    cv2.circle(image1,(centers[i][0],centers[i][1]),2,(0,0,255),2)\n",
    "\n",
    "# show the image on screen\n",
    "\n",
    "#cv2.imshow('image', image1)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "cv2.imwrite('./image_result/final_image_1.png', image1)\n",
    "\n",
    "parking_spaces.shape\n",
    "\n",
    "car_boxes2.shape\n",
    "\n",
    "# How much car overlaps with the bounding boxes of parking spaces\n",
    "\n",
    "overlaps = mrcnn.utils.compute_overlaps(car_boxes2[0],parking_spaces)\n",
    "\n",
    "overlaps.shape\n",
    "\n",
    "overlap_prob = overlaps.sum(axis=0)\n",
    "\n",
    "for i,box in enumerate(parking_spaces):\n",
    "    y1, x1, y2, x2 = box\n",
    "    \n",
    "    if overlap_prob[i] >= 0.5:\n",
    "        occupancy_status = (0,0,255)\n",
    "    \n",
    "    else:\n",
    "        occupancy_status = (0,255,0)\n",
    "    cv2.rectangle(image2,(x1,y1), (x2,y2) , occupancy_status ,1)\n",
    "    cv2.circle(image2,(centers[i][0],centers[i][1]),2,occupancy_status,2)\n",
    "        \n",
    "\n",
    "\n",
    "cv2.imwrite('./image_result/final_image_2.png', image2)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
